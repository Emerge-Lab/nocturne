# Base paths 
bc_models_dir: models/il
hr_ppo_models_dir_self_play: models/hr_rl/0130_paper/ma_s1000
hr_ppo_models_dir_log_replay: models/hr_rl/0130_paper/sa_s1000
small_data_bc_models_dir: models/il/small_data
small_data_hr_ppo_models_dir: models/hr_rl/0130_paper/small_data

# Aggregate performance table 
best_overall_models: 
  - name: policy_L0.0_S1000_I1212
    agent: PPO
    reg_weight: 0.0 
    train_agent: Self-play
    wandb_run: 

  - name: policy_L0.02_S1000_I1654
    reg_weight: 0.02
    agent: HR-PPO
    train_agent: Self-play
    wandb_run: magic-frost-373

  - name: policy_L0.025_S1000_I3250
    reg_weight: 0.025
    agent: HR-PPO
    train_agent: Self-play
    wandb_run: deep-bush-33

  - name: policy_L0.05_S1000_I3431
    reg_weight: 0.05
    agent: HR-PPO
    train_agent: Self-play
    wandb_run: resilient-sunset-338

# Human likeness vs. performance
trade_off_analysis: 
  - name: policy_L0.0_S1000_I1212
    agent: PPO
    reg_weight: 0.0 
    train_agent: Self-play
    wandb_run: 

  - name: policy_L0.005_S1000_I2250
    reg_weight: 0.005
    agent: HR-PPO
    train_agent: Self-play
    wandb_run: sage-butterfly-341

  - name: policy_L0.01_S1000_I3459
    reg_weight: 0.01
    agent: HR-PPO
    train_agent: Self-play
    wandb_run: treasured-waterfall-339

  - name: policy_L0.025_S1000_I3250
    reg_weight: 0.025
    agent: HR-PPO
    train_agent: Self-play
    wandb_run: deep-bush-33

  - name: policy_L0.05_S1000_I3431
    reg_weight: 0.05
    agent: HR-PPO
    train_agent: Self-play
    wandb_run: resilient-sunset-338

used_human_policy: # The human reference policy used for HR-PPO
  - name: human_policy_D99_S1000_01_29_11_53
    agent: BC
    train_agent: '-'
    wandb_run: '-'

small_data_il: # How much data do we need for better coordination?
  # - name: human_policy_D99_S13_FILTERED_01_29_14_46 # PPO-only baseline
  #   type: "filtered"
  #   samples: 5000

  # - name: human_policy_D99_S104_FILTERED_01_29_14_02
  #   type: "filtered"
  #   samples: 20_000

  - name: human_policy_D99_S436_FILTERED_01_29_15_15
    type: "filtered"
    samples: 100_000

  # - name: human_policy_D99_S10_UNFILTERED_01_29_15_57
  #   type: "unfiltered"
  #   samples: 5000
    
  # - name: human_policy_D99_S57_UNFILTERED_01_29_15_31
  #   type: "unfiltered"
  #   samples: 20_000

  # - name: human_policy_D99_S283_UNFILTERED_01_29_16_38
  #   type: "unfiltered"
  #   samples: 100_000

small_data_hr_ppo:
  - name: policy_L0.0_S1000_I1212
    type: "baseline"
    agent: PPO
    samples: 0

  - name: policy_L0.02_S1000_I2953_S13_FILTERED
    type: "filtered"
    agent: HR-PPO
    samples: 5000
    wandb_run: serene-puddle-352
  
  - name: policy_L0.02_S1000_I2750_S57_UNFILTERED
    type: "unfiltered"
    agent: HR-PPO
    samples: 20_000
    wandb_run: true-dust-356

  - name: policy_L0.02_S1000_I1750_S436_FILTERED
    type: "filtered"
    agent: HR-PPO
    samples: 100_000
    wandb_run: misty-blaze-364